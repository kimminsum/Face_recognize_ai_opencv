{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label: dict = {0: \"가위\", 1: \"보\"}\n",
    "img_size: int = 50\n",
    "epoch: int = 1000\n",
    "img_number: int = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "\n",
    "img_path = \"test_img\"\n",
    "\n",
    "for i in range(img_number):\n",
    "    try:\n",
    "        img_list.append(Image.open(f\"{img_path}/{i}.jpg\").convert(\"L\"))\n",
    "    except:\n",
    "        try:\n",
    "            img_list.append(Image.open(f\"{img_path}/{i}.jpeg\").convert(\"L\"))\n",
    "        except:\n",
    "            img_list.append(Image.open(f\"{img_path}/{i}.png\").convert(\"L\"))\n",
    "### ###\n",
    "plt.imshow(img_list[0], cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img_list = []\n",
    "\n",
    "for i in range(img_number):\n",
    "    resized_img_list.append(np.array(img_list[i].resize((img_size, img_size))).reshape(1, -1)[0]/255.)\n",
    "\n",
    "X = np.array(resized_img_list)\n",
    "### ###\n",
    "y_list = []\n",
    "\n",
    "for i in range(20):\n",
    "    y_list.append(0)\n",
    "for j in range(30):\n",
    "    y_list.append(1)\n",
    "\n",
    "Y = np.array(y_list)\n",
    "### ###\n",
    "plt.imshow(np.array(img_list[0].resize((img_size, img_size)))/255., cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the model and Train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=[img_size**2,]),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train the data\n",
    "history = model.fit(X, Y,\n",
    "          epochs=train_times,\n",
    "          batch_size= 10,\n",
    "          validation_split=0.25)\n",
    "\n",
    "# train history visualization(accuracy)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 7 train history visualization(loss)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"obstacle_detection.h5\")\n",
    "new_model = tf.keras.models.load_model(\"obstacle_detection.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = Image.open(f\"{img_path}/5.jpg\").convert(\"L\")\n",
    "img = np.array(test_img.resize((img_size, img_size))).reshape(1, -1)[0]/255.\n",
    "plt.imshow(np.array(test_img), cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(label[new_model.predict(np.array([img])).argmax()]) # show what object is\n",
    "print(label[new_model.predict(np.array([img])).argmax()]==\"가위\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
